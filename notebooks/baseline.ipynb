{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "531dda4f",
   "metadata": {},
   "source": [
    "# KLUE-RE Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300a2508",
   "metadata": {},
   "source": [
    "## Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de17882b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from functools import partial\n",
    "from typing import Tuple, List, Any, Dict\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "import transformers\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    ")\n",
    "from transformers import TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0cec8c",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "446c1a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 3e-05\n",
    "num_train_epochs = 4\n",
    "train_batch_size = 32\n",
    "eval_batch_size = 32\n",
    "warmup_ratio = 0.2\n",
    "# patience = 10000\n",
    "output_dir = \"klue_dir\"\n",
    "wandb_project = \"klue_re\"\n",
    "run_name = \"baseline\"\n",
    "report_to = \"wandb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa84097c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_or_path = \"klue/roberta-large\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0855bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "markers = dict(\n",
    "    subject_start_marker=\"<subj>\",\n",
    "    subject_end_marker=\"</subj>\",\n",
    "    object_start_marker=\"<obj>\",\n",
    "    object_end_marker=\"</obj>\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17cbd6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "relation_class = [\n",
    "    \"no_relation\",\n",
    "    \"org:dissolved\",\n",
    "    \"org:founded\",\n",
    "    \"org:place_of_headquarters\",\n",
    "    \"org:alternate_names\",\n",
    "    \"org:member_of\",\n",
    "    \"org:members\",\n",
    "    \"org:political/religious_affiliation\",\n",
    "    \"org:product\",\n",
    "    \"org:founded_by\",\n",
    "    \"org:top_members/employees\",\n",
    "    \"org:number_of_employees/members\",\n",
    "    \"per:date_of_birth\",\n",
    "    \"per:date_of_death\",\n",
    "    \"per:place_of_birth\",\n",
    "    \"per:place_of_death\",\n",
    "    \"per:place_of_residence\",\n",
    "    \"per:origin\",\n",
    "    \"per:employee_of\",\n",
    "    \"per:schools_attended\",\n",
    "    \"per:alternate_names\",\n",
    "    \"per:parents\",\n",
    "    \"per:children\",\n",
    "    \"per:siblings\",\n",
    "    \"per:spouse\",\n",
    "    \"per:other_family\",\n",
    "    \"per:colleagues\",\n",
    "    \"per:product\",\n",
    "    \"per:religion\",\n",
    "    \"per:title\"\n",
    "]\n",
    "\n",
    "num_labels = len(relation_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efaa8d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {idx: label for idx, label in enumerate(relation_class)}\n",
    "label2id = {label: idx for idx, label in enumerate(relation_class)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf81eb8",
   "metadata": {},
   "source": [
    "## Load and Preprocess Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5ee0896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "050a25a2704544388324a7540cec2610",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/5.19k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12aee463f31747bbb0da388a9f1925ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.93k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset klue/re (download: 5.41 MiB, generated: 13.07 MiB, post-processed: Unknown size, total: 18.48 MiB) to /opt/ml/.cache/huggingface/datasets/klue/re/1.0.0/55ff8f92b7a4b9842be6514ce0b4b5295b46d5e493f8bb5760da4be717018f90...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b15592b70ded466eb69095ec3b32b5fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/5.67M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset klue downloaded and prepared to /opt/ml/.cache/huggingface/datasets/klue/re/1.0.0/55ff8f92b7a4b9842be6514ce0b4b5295b46d5e493f8bb5760da4be717018f90. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d87c15f9e3f42cbb2bd5a9d8d430fbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "klue_re = load_dataset(\"klue\", \"re\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f14ddf5f-a3ea-4e0a-897d-1fc3ace8b7df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['guid', 'sentence', 'subject_entity', 'object_entity', 'label', 'source'],\n",
       "        num_rows: 32470\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['guid', 'sentence', 'subject_entity', 'object_entity', 'label', 'source'],\n",
       "        num_rows: 7765\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "klue_re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1bcdf29b-fd44-4119-a72d-bb6715c3405e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'guid': Value(dtype='string', id=None),\n",
       " 'sentence': Value(dtype='string', id=None),\n",
       " 'subject_entity': {'word': Value(dtype='string', id=None),\n",
       "  'start_idx': Value(dtype='int32', id=None),\n",
       "  'end_idx': Value(dtype='int32', id=None),\n",
       "  'type': Value(dtype='string', id=None)},\n",
       " 'object_entity': {'word': Value(dtype='string', id=None),\n",
       "  'start_idx': Value(dtype='int32', id=None),\n",
       "  'end_idx': Value(dtype='int32', id=None),\n",
       "  'type': Value(dtype='string', id=None)},\n",
       " 'label': ClassLabel(num_classes=30, names=['no_relation', 'org:dissolved', 'org:founded', 'org:place_of_headquarters', 'org:alternate_names', 'org:member_of', 'org:members', 'org:political/religious_affiliation', 'org:product', 'org:founded_by', 'org:top_members/employees', 'org:number_of_employees/members', 'per:date_of_birth', 'per:date_of_death', 'per:place_of_birth', 'per:place_of_death', 'per:place_of_residence', 'per:origin', 'per:employee_of', 'per:schools_attended', 'per:alternate_names', 'per:parents', 'per:children', 'per:siblings', 'per:spouse', 'per:other_family', 'per:colleagues', 'per:product', 'per:religion', 'per:title'], names_file=None, id=None),\n",
       " 'source': Value(dtype='string', id=None)}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "klue_re['train'].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "85eeefc2-09e4-4947-ba16-6dbbd3311187",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'guid': 'klue-re-v1_train_00000',\n",
       " 'sentence': '〈Something〉는 조지 해리슨이 쓰고 비틀즈가 1969년 앨범 《Abbey Road》에 담은 노래다.',\n",
       " 'subject_entity': {'word': '비틀즈',\n",
       "  'start_idx': 24,\n",
       "  'end_idx': 26,\n",
       "  'type': 'ORG'},\n",
       " 'object_entity': {'word': '조지 해리슨',\n",
       "  'start_idx': 13,\n",
       "  'end_idx': 18,\n",
       "  'type': 'PER'},\n",
       " 'label': 0,\n",
       " 'source': 'wikipedia'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "klue_re['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "44a995e8-3151-41a8-9afd-6266b9385d1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(klue_re['train']['subject_entity'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e9bb19",
   "metadata": {},
   "source": [
    "### Load tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dcbc001c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/basic/lib/python3.8/site-packages/transformers/configuration_utils.py:336: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aacf15a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_example\n",
    "def mark_entity_spans(examples,\n",
    "                      subject_start_marker: str, subject_end_marker: str,\n",
    "                      object_start_marker: str, object_end_marker: str):\n",
    "\n",
    "    def _mark_entity_spans(\n",
    "        text: str, \n",
    "        subject_range=Tuple[int, int], \n",
    "        object_range=Tuple[int, int]\n",
    "    ) -> str:\n",
    "        \"\"\" Adds entity markers to the text to identify the subject/object entities.\n",
    "        Args:\n",
    "            text: Original sentence\n",
    "            subject_range: Pair of start and end indices of subject entity\n",
    "            object_range: Pair of start and end indices of object entity\n",
    "        Returns:\n",
    "            A string of text with subject/object entity markers\n",
    "        \"\"\"\n",
    "        if subject_range < object_range:\n",
    "            segments = [\n",
    "                text[: subject_range[0]],\n",
    "                subject_start_marker,\n",
    "                text[subject_range[0] : subject_range[1] + 1],\n",
    "                subject_end_marker,\n",
    "                text[subject_range[1] + 1 : object_range[0]],\n",
    "                object_start_marker,\n",
    "                text[object_range[0] : object_range[1] + 1],\n",
    "                object_end_marker,\n",
    "                text[object_range[1] + 1 :],\n",
    "            ]\n",
    "        elif subject_range > object_range:\n",
    "            segments = [\n",
    "                text[: object_range[0]],\n",
    "                object_start_marker,\n",
    "                text[object_range[0] : object_range[1] + 1],\n",
    "                object_end_marker,\n",
    "                text[object_range[1] + 1 : subject_range[0]],\n",
    "                subject_start_marker,\n",
    "                text[subject_range[0] : subject_range[1] + 1],\n",
    "                subject_end_marker,\n",
    "                text[subject_range[1] + 1 :],\n",
    "            ]\n",
    "        else:\n",
    "            raise ValueError(\"Entity boundaries overlap.\")\n",
    "\n",
    "        marked_text = \"\".join(segments)\n",
    "\n",
    "        return marked_text\n",
    "    \n",
    "    subject_entity = examples[\"subject_entity\"]\n",
    "    object_entity = examples[\"object_entity\"]\n",
    "    \n",
    "    text = _mark_entity_spans(\n",
    "        examples[\"sentence\"],\n",
    "        (subject_entity[\"start_idx\"], subject_entity[\"end_idx\"]),\n",
    "        (object_entity[\"start_idx\"], object_entity[\"end_idx\"]),\n",
    "    )\n",
    "    return {\"text\": text}\n",
    "\n",
    "mark_entity_spans = partial(mark_entity_spans, **markers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4a3f23eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f674ca6fe97e4498b8049b451f66e8a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32470 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fb82b7278314d719b5f014e11c055b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7765 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "examples = klue_re.map(mark_entity_spans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9e058aa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.add_special_tokens(\n",
    "    {\"additional_special_tokens\": list(markers.values())}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "454fd944",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_example_to_features(\n",
    "    examples, \n",
    "    tokenizer,\n",
    "    subject_start_marker: str,\n",
    "    subject_end_marker: str,\n",
    "    object_start_marker: str,\n",
    "    object_end_marker: str\n",
    ") -> Dict[str, List[Any]]:\n",
    "    \n",
    "    def fix_tokenization_error(text: str) -> List[str]:\n",
    "        \"\"\"Fix the tokenization due to the `obj` and `subj` marker inserted\n",
    "        in the middle of a word.\n",
    "        Example:\n",
    "            >>> text = \"<obj>조지 해리슨</obj>이 쓰고 <subj>비틀즈</subj>가\"\n",
    "            >>> tokens = ['<obj>', '조지', '해리', '##슨', '</obj>', '이', '쓰', '##고', '<subj>', '비틀즈', '</subj>', '가']\n",
    "            >>> fix_tokenization_error(text)\n",
    "            ['<obj>', '조지', '해리', '##슨', '</obj>', '##이', '쓰', '##고', '<subj>', '비틀즈', '</subj>', '##가']\n",
    "            \n",
    "        Only support for BertTokenizerFast\n",
    "        If you use bbpe, change code!\n",
    "        \"\"\"\n",
    "        batch_encoding = tokenizer._tokenizer.encode(text)\n",
    "        tokens = batch_encoding.tokens\n",
    "        # subject\n",
    "        if text[text.find(subject_end_marker) + len(subject_end_marker)] != \" \":\n",
    "            space_idx = tokens.index(subject_end_marker) + 1\n",
    "            # tokenizer_type == \"bert-wp\"\n",
    "            if not tokens[space_idx].startswith(\"##\") and \"가\" <= tokens[space_idx][0] <= \"힣\":\n",
    "                tokens[space_idx] = \"##\" + tokens[space_idx]\n",
    "\n",
    "        # object\n",
    "        if text[text.find(object_end_marker) + len(object_end_marker)] != \" \":\n",
    "            space_idx = tokens.index(object_end_marker) + 1\n",
    "            # tokenizer_type == \"bert-wp\"\n",
    "            if not tokens[space_idx].startswith(\"##\") and \"가\" <= tokens[space_idx][0] <= \"힣\":\n",
    "                tokens[space_idx] = \"##\" + tokens[space_idx]\n",
    "        \n",
    "        return tokens    \n",
    "    \n",
    "    tokens = fix_tokenization_error(examples[\"text\"])\n",
    "    \n",
    "    return {\n",
    "        \"input_ids\": tokenizer.convert_tokens_to_ids(tokens),\n",
    "        \"tokenized\": tokens,\n",
    "    }\n",
    "\n",
    "convert_example_to_features = partial(\n",
    "    convert_example_to_features,\n",
    "    tokenizer=tokenizer,\n",
    "    **markers,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ef78a2a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f838549d6174f50aa36d490be052578",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32470 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5b136f977d74514864d661dd6bbd7d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7765 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets = examples.map(convert_example_to_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6379b0d9-0aaf-4788-99c1-628fb479b19d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['guid', 'sentence', 'subject_entity', 'object_entity', 'label', 'source', 'text', 'input_ids', 'tokenized'],\n",
       "        num_rows: 32470\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['guid', 'sentence', 'subject_entity', 'object_entity', 'label', 'source', 'text', 'input_ids', 'tokenized'],\n",
       "        num_rows: 7765\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c4778f9b-d1fd-4c73-8605-f24f7ef11c84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets['train']['label'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72864c72",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a5ba0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AutoConfig.from_pretrained(\n",
    "    pretrained_model_name_or_path=model_name_or_path,\n",
    "    num_labels=num_labels,\n",
    "    cache_dir=\"cache\",\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6882f9fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'klue/roberta-large'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config._name_or_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a23fbe24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at klue/roberta-large were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.decoder.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    pretrained_model_name_or_path=model_name_or_path,\n",
    "    config=config,\n",
    "    cache_dir=\"cache\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f0196c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resize...\n"
     ]
    }
   ],
   "source": [
    "if model.config.vocab_size < len(tokenizer):\n",
    "    print(\"resize...\")\n",
    "    model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271e7f4c",
   "metadata": {},
   "source": [
    "## Make compute metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b64c649",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_recall_curve, auc\n",
    "\n",
    "\n",
    "def make_compute_metrics(label_indices):\n",
    "    n_classes = len(label_indices)\n",
    "    no_relation_label_idx = label_indices.index(\"no_relation\")\n",
    "    label_indices = list(range(len(relation_class)))\n",
    "    label_indices.remove(no_relation_label_idx)\n",
    "    \n",
    "    def compute_metrics(eval_pred, label_indices=label_indices, n_classes=n_classes):\n",
    "        preds, labels = eval_pred\n",
    "\n",
    "        # Micro F1 (except no_relation)\n",
    "        predictions = np.argmax(preds, axis=1).ravel()\n",
    "        micro_f1 = f1_score(labels, predictions, average=\"micro\", labels=label_indices)\n",
    "\n",
    "        # AUPRC (Area Under the Precision-Recall Curve)\n",
    "        onehots = np.eye(n_classes)[labels]\n",
    "        scores = np.zeros((n_classes,))\n",
    "        for c in range(n_classes):\n",
    "            targets_c = onehots.take([c], axis=1).ravel()\n",
    "            preds_c = preds.take([c], axis=1).ravel()\n",
    "            precision, recall, _ = precision_recall_curve(targets_c, preds_c)\n",
    "            scores[c] = auc(recall, precision)\n",
    "        auprc = np.average(scores)\n",
    "\n",
    "        return {\n",
    "            \"micro_f1\": micro_f1,\n",
    "            \"auprc\": auprc,\n",
    "        }\n",
    "    \n",
    "    return compute_metrics\n",
    "\n",
    "compute_metrics = make_compute_metrics(relation_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b031ef4",
   "metadata": {},
   "source": [
    "## Make Data Collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "503cd2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataCollator:\n",
    "    \n",
    "    def __init__(self, tokenizer, max_length=510):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __call__(self, batch):\n",
    "        input_ids = [x[\"input_ids\"] for x in batch]\n",
    "        labels = [x[\"label\"] for x in batch]\n",
    "        batch_encoding = tokenizer.pad(\n",
    "            {\"input_ids\": input_ids},\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        batch_encoding.update({\"labels\": torch.LongTensor(labels)})\n",
    "        return batch_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "283d6128",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollator(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9a442fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjinmang2\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"WANDB_PROJECT\"] = wandb_project\n",
    "\n",
    "call_wandb = True\n",
    "try:\n",
    "    os.environ[\"WANDB_PROJECT\"]\n",
    "    \n",
    "except KeyError:\n",
    "    call_wandb = False\n",
    "    \n",
    "if call_wandb:\n",
    "    import wandb\n",
    "    wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "725c83e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=learning_rate,\n",
    "    per_device_train_batch_size=train_batch_size,\n",
    "    per_device_eval_batch_size=eval_batch_size,\n",
    "    weight_decay=0.01,\n",
    "    warmup_ratio=warmup_ratio,\n",
    "#     save_total_limit=5,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    fp16=True,\n",
    "    report_to=report_to,\n",
    "    run_name=run_name,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"auprc\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "63a5f1c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'input_ids'],\n",
       "        num_rows: 32470\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['label', 'input_ids'],\n",
       "        num_rows: 7765\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_name = list(tokenized_datasets[\"train\"].features.keys())\n",
    "features_name.pop(features_name.index(\"input_ids\"))\n",
    "features_name.pop(features_name.index(\"label\"))\n",
    "tokenized_datasets = tokenized_datasets.remove_columns(features_name)\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2204de6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datasets import DatasetDict\n",
    "\n",
    "# tokenized_datasets = DatasetDict(\n",
    "#     {\n",
    "#         \"train\": tokenized_datasets[\"train\"].select(range(1000)),\n",
    "#         \"validation\": tokenized_datasets[\"validation\"].select(range(1000)),\n",
    "#     }\n",
    "# )\n",
    "# tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bb95f9f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp fp16 backend\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "869ceeec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 32470\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 10150\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "\n",
      "CondaEnvException: Unable to determine environment\n",
      "\n",
      "Please re-run this command with one of the following options:\n",
      "\n",
      "* Provide an environment name via --name or -n\n",
      "* Re-run this command inside an activated conda environment.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.2<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">baseline</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/jinmang2/klue_re\" target=\"_blank\">https://wandb.ai/jinmang2/klue_re</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/jinmang2/klue_re/runs/oa9e1uth\" target=\"_blank\">https://wandb.ai/jinmang2/klue_re/runs/oa9e1uth</a><br/>\n",
       "                Run data is saved locally in <code>/opt/ml/klue_re/wandb/run-20210919_183205-oa9e1uth</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6656' max='10150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 6656/10150 42:45 < 22:27, 2.59 it/s, Epoch 6.56/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Micro F1</th>\n",
       "      <th>Auprc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.836800</td>\n",
       "      <td>0.893166</td>\n",
       "      <td>0.567788</td>\n",
       "      <td>0.563350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.587700</td>\n",
       "      <td>0.866404</td>\n",
       "      <td>0.605545</td>\n",
       "      <td>0.689716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.451700</td>\n",
       "      <td>0.721395</td>\n",
       "      <td>0.670039</td>\n",
       "      <td>0.736213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.327900</td>\n",
       "      <td>0.691364</td>\n",
       "      <td>0.697971</td>\n",
       "      <td>0.743833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.238600</td>\n",
       "      <td>0.895599</td>\n",
       "      <td>0.673916</td>\n",
       "      <td>0.726725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.169200</td>\n",
       "      <td>0.950437</td>\n",
       "      <td>0.674746</td>\n",
       "      <td>0.725315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/basic/lib/python3.8/site-packages/transformers/trainer.py:1337: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  nn.utils.clip_grad_norm_(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 7765\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to klue_dir/checkpoint-1015\n",
      "Configuration saved in klue_dir/checkpoint-1015/config.json\n",
      "Model weights saved in klue_dir/checkpoint-1015/pytorch_model.bin\n",
      "/opt/conda/envs/basic/lib/python3.8/site-packages/transformers/trainer.py:1337: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  nn.utils.clip_grad_norm_(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 7765\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to klue_dir/checkpoint-2030\n",
      "Configuration saved in klue_dir/checkpoint-2030/config.json\n",
      "Model weights saved in klue_dir/checkpoint-2030/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 7765\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to klue_dir/checkpoint-3045\n",
      "Configuration saved in klue_dir/checkpoint-3045/config.json\n",
      "Model weights saved in klue_dir/checkpoint-3045/pytorch_model.bin\n",
      "/opt/conda/envs/basic/lib/python3.8/site-packages/transformers/trainer.py:1337: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  nn.utils.clip_grad_norm_(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 7765\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to klue_dir/checkpoint-4060\n",
      "Configuration saved in klue_dir/checkpoint-4060/config.json\n",
      "Model weights saved in klue_dir/checkpoint-4060/pytorch_model.bin\n",
      "/opt/conda/envs/basic/lib/python3.8/site-packages/transformers/trainer.py:1337: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  nn.utils.clip_grad_norm_(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 7765\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to klue_dir/checkpoint-5075\n",
      "Configuration saved in klue_dir/checkpoint-5075/config.json\n",
      "Model weights saved in klue_dir/checkpoint-5075/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 7765\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to klue_dir/checkpoint-6090\n",
      "Configuration saved in klue_dir/checkpoint-6090/config.json\n",
      "Model weights saved in klue_dir/checkpoint-6090/pytorch_model.bin\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fc9b46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basic",
   "language": "python",
   "name": "basic"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
